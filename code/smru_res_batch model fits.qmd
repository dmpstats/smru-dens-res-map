---
title: "smru RES batch fit"
format: html
editor: visual
---

## Overview

```{r}
#| include: false

library(tidyverse)
library(here)
source("tools.R")


```

## Read and prep data in bulk

```{r}

infileList <- list.files(here("NE Atlantic Data"), recursive = F, full.names = T) 
infileList <- infileList[str_detect(infileList, "\\.csv")]

dataList <- map(infileList, read_csv)

rawSpecies <- bind_rows(dataList) %>% 
  rename(UpperCI = CI_95_high,
         LowerCI = CI_95_low) 

```

```{r}
# Adding survey uncertainty -------------------------------------------------------------------
#' Here devise resampling for the different sorts of uncertainty that are present in the survey data
#' Note, there are single measures and upper/lower 95% CIS
#' 

table(rawSpecies$Uncertainty_measure, useNA = "always")

# check that where there is not a single measure, we do have a CI
test <- rawSpecies %>% filter(is.na(Uncertainty_measure)) 

test %>% filter(!is.na(LowerCI))

test <- rawSpecies %>% 
  mutate(Uncertainty_measure = ifelse(is.na(Uncertainty_measure) & !is.na(LowerCI), "Confint", Uncertainty_measure)) %>%
  filter(!(is.na(Uncertainty_measure) & is.na(UpperCI))) 

table(test$Uncertainty_measure, useNA = "always")
```

Basic approach here is to convert *everything* to a standard error. This is done either directly for CVs (noting some are %-age), SEs for abundance, SEs as given, or inferred from confidence intervals assuming that these are log-Normally distributed.

```{r}
# note some have CIs and alterative measure. Will use CIs when available
# %-age CV looks to just be CV * 100
# convert to CVs, extract as CIs so single sampling method required
# everything in the data with a CV provided a CI as well

speciesData <- rawSpecies %>%
  mutate(Uncertainty_measure = ifelse(is.na(Uncertainty_measure) & !is.na(LowerCI), "Confint", Uncertainty_measure)) %>% # input Confint where we have them, drop where we can't ID uncertainty
  filter(!(is.na(Uncertainty_measure) & is.na(UpperCI))) %>% 
  filter(!(is.na(Uncertainty) & is.na(UpperCI))) %>% 
  mutate(Uncertainty = ifelse(str_detect(Uncertainty_measure, "CV") & Uncertainty > 4, Uncertainty/100, Uncertainty), # looks like various % errors 
         Uncertainty = ifelse(str_detect(Uncertainty_measure, "% CV abundance"), Uncertainty/100, Uncertainty), 
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "% CV for abundance"), "CV", Uncertainty_measure), 
         Uncertainty = ifelse(str_detect(Uncertainty_measure, "CV"), Uncertainty*Density, Uncertainty),
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "CV"), "SE", Uncertainty_measure),
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "SE density"), "SE", Uncertainty_measure),
         Uncertainty = ifelse(str_detect(Uncertainty_measure, "Variance of density"), sqrt(Uncertainty), Uncertainty),
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "Variance of density"), "SE", Uncertainty_measure),
         Uncertainty = ifelse(str_detect(Uncertainty_measure, "Variance of abundance"), NA, Uncertainty), # all these have CIs
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "Variance of abundance"), "Confint", Uncertainty_measure),
         Uncertainty = ifelse(str_detect(Uncertainty_measure, "SE abundance"), NA, Uncertainty), # all these have CIs
         Uncertainty_measure = ifelse(str_detect(Uncertainty_measure, "SE abundance"), "Confint", Uncertainty_measure),
         workingSE = Uncertainty
  )

```


Correct for situations where the density has been converted to a different scale, but SE has not e.g. 100km2 to 1km2.


```{r}

speciesData %>% 
  mutate(CV = workingSE/Density) %>% 
  filter(Uncertainty_measure == "SE" & CV > 2) %>% 
  group_by(Internal_reference) %>% 
  summarise(N = n())

```


```{r}

speciesData %>% 
  mutate(CV = workingSE/Density) %>% 
  filter(str_detect(Internal_reference, "015_Harwood|055_Stone|091_Sagnol")) %>% 
  group_by(Internal_reference) %>% 
  summarise(N = n())

```

So we need only correct for these data sources in totality - there are only SE.



```{r}

speciesData <- speciesData %>% 
  mutate(workingSE = if_else(str_detect(Internal_reference, "015_Harwood|055_Stone|091_Sagnol"), workingSE/100, workingSE))

```


Now require SE where we have only CIs. Many don't seem consistent with the lognormal (appear very approximate - suspect have been hacked, particularly with zero lower bounds)



```{r}

temp <- speciesData %>% 
  select(Uncertainty_measure, Uncertainty, Density, LowerCI, UpperCI) %>% 
  filter(Uncertainty_measure == "Confint") %>% 
  mutate(ratio = (UpperCI - LowerCI)/Density,
         SE = SEfromCI(Density, LowerCI, UpperCI),
         CV = SE/Density) 


```

The rationale here therefore is to use the lognormal to generate, except for where it fails (Inf returned). This is where we have 0 lower CI, which themselves appear to be hacked. In these cases, assume SE is the CI range/2*1.96 - which appears reasonable for these few cases. Suspect these have been generated from a normal approximation, with an arbitrary bounding at zero.





```{r}

speciesData <- speciesData %>% 
  mutate(workingSE = if_else(Uncertainty_measure == "Confint", SEfromCI(Density, LowerCI, UpperCI), workingSE),
         workingSE = if_else(is.infinite(workingSE), (UpperCI - LowerCI)/(2*1.96), workingSE), 
         CV = workingSE/Density) 


```


Will be sampling from lognormal, check these aren't wildly contradictory where we have CIs to compare to.


```{r}
# obtain CIs from lognormal using mean, SE

speciesData <- speciesData %>%
  mutate(workingLowerCI = qlnorm(0.025, logMu(Density, workingSE), logSigma(Density, workingSE)),
         workingUpperCI = qlnorm(0.975, logMu(Density, workingSE), logSigma(Density, workingSE)),
         lowerError = LowerCI - workingLowerCI, 
         upperError = UpperCI - workingUpperCI,
         blockID = Survey
  ) 

```




```{r}

summary(speciesData$lowerError)
summary(speciesData$upperError)

```


```{r}

speciesData %>% 
  mutate(errorRatio = abs(upperError)/UpperCI) %>% 
  filter(errorRatio > 1)

```



```{r}
# file is too large for github

write_csv(speciesData, here("C:/Users/crd2/Dropbox/dmp/clients/smru/resMap_NE2024/"))

```

## Modelling batch

```{r}

speciesData <- read_csv("C:/Users/crd2/Dropbox/dmp/clients/smru/resMap_NE2024/data/smru_RES_cleaned density data.csv")

speciesData %>% 
  group_by(Commonname, Location) %>% 
  summarise(dataSupport = n()) %>% 
  mutate(wholeData = T,
         northData = str_detect(Location, "North"),
         atlanticData = str_detect(Location, "Atlantic"),
         northEast = str_detect(Location, "Northeast")) %>% 
  print(n = 100)
         


```

### blue whale

```{r}

speciesName <- "sperm"  
locationName <- "north"
nBoot <- 500


dataList <- split(speciesData, speciesData$blockID)

set.seed(345)

sampleList <- lapply(dataList, function(q){sampleLN(q$Density[1], q$workingSE[1], nBoot)})

sampleDF <- plyr::ldply(sampleList) %>%
  rename(Survey = .id)

speciesSamples <- speciesData %>% left_join(sampleDF)


speciesSamples <- speciesSamples %>% 
  select(-Density) %>%
  pivot_longer(names_to = "sampleID", values_to = "Density", V1:last_col()) 


speciesList <- split(speciesSamples, speciesSamples$sampleID)


# fittedList <- lapply(speciesList, gamFit, inRES = data.frame(RES = seq(0, 1, by = 0.01))) 

plan(multicore, workers = 10)

testFN <- function(inList){
  
  p <- progressor(steps = length(inList))
  
  future_map(inList, \(x) {p(); gamFitTweedie(x, inP = 1.2, inRES = data.frame(RES = seq(0, 1, by = 0.01)))})
  
}


with_progress({
  fittedList <- testFN(speciesList)
})


fittedDF <- fittedList %>%
  bind_rows()

fittedMatrix <- matrix(fittedDF$Pred, ncol = nBoot)

test <- t(apply(fittedMatrix, 1, function(q){quantile(q, probs = c(0.025, 0.5, 0.975))}))

testSE <- apply(fittedMatrix, 1, sd)

resFits <- as.data.frame(test) %>%
  mutate(RES = seq(0, 1, by = 0.01), SE = testSE) %>%
  rename(lower = `2.5%`, med = `50%`, upper = `97.5%`) %>%
  mutate(med = ifelse(med < 0, min(abs(med)), med),
         CV = SE/med) %>%
  #CV = ifelse(CV > 2, 2, CV)) %>%
  arrange(RES)

plottingDF <- resFits

bootPlot <- ggplot(plottingDF) +
  ggthemes::theme_fivethirtyeight() +
  #geom_point(data = ribbonsealData, aes(RES, Density), size = 2, alpha = 0.2) +
  geom_line(aes(RES, med), size = 2, alpha = 0.7, col = "purple") +
  geom_ribbon(aes(x = RES, ymin = lower, ymax = upper), fill = "purple", alpha = 0.2) +
  ggtitle("Density as function of RES", paste0(speciesName, " whale: bootstrapped monotone spline fits"))

bootPlot

ggsave(paste0("docs/images/", speciesName, "_", locationName, "_bootplot_", nBoot, ".png"), units = "cm", width = 30, height = 20)
saveRDS(plottingDF, paste0("data/plotting components/", speciesName, "_", locationName, "_plotElements",".rds"))


# Create RES grid predictions -----------------------------------------------------------------

resFits <- resFits %>% select(med, RES, CV) %>%
  rename(PredDensity = med) %>%
  mutate(RES = round(RES, 2))

predictionOutput <- resGrid %>% left_join(resFits, by = "RES")

predictionOutput <- predictionOutput %>%
  mutate(PredDensity = ifelse(RES == 0, 0, PredDensity),
         CV = ifelse(RES == 0, NA, CV))

summary(predictionOutput)



write.csv(predictionOutput, file = paste0("data/predictions/", speciesName, "_", locationName, "_predictions.csv"), row.names = F)


```

### Bowhead whle

### Brydes whale

### Fin whale

### Humpback whale

### Minke whale

### North atlantic right whale

### Sei whale

### Sperm whale
